services:
  # PostgreSQL with TimescaleDB - Enhanced with resource limits and improved health checks
  postgres:
    image: timescale/timescaledb:latest-pg16
    container_name: securewatch_postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./create_tables.sql:/docker-entrypoint-initdb.d/01_init_schema.sql
      - ./infrastructure/database/correlation_schema.sql:/docker-entrypoint-initdb.d/02_correlation_schema.sql
      - ./infrastructure/database/continuous_aggregates.sql:/docker-entrypoint-initdb.d/03_continuous_aggregates.sql
      - ./infrastructure/database/lookup_schema.sql:/docker-entrypoint-initdb.d/04_lookup_schema.sql
    environment:
      POSTGRES_USER: securewatch
      POSTGRES_PASSWORD: securewatch_dev
      POSTGRES_DB: securewatch
      TS_TUNE_MEMORY: "2GB"
      TS_TUNE_NUM_CPUS: "2"
      POSTGRES_SHARED_PRELOAD_LIBRARIES: timescaledb
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_WORK_MEM: 16MB
      POSTGRES_MAINTENANCE_WORK_MEM: 256MB
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U securewatch -d securewatch"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s  # Give TimescaleDB time to initialize
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    networks:
      - securewatch_network

  # Redis - Enhanced with resource limits and improved configuration
  redis:
    image: redis:7-alpine
    container_name: securewatch_redis_master
    ports:
      - "6379:6379"
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass securewatch_dev
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --tcp-keepalive 300
      --timeout 300
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "securewatch_dev", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.25'
    restart: unless-stopped
    networks:
      - securewatch_network

  # MCP Marketplace Service - Enhanced with resource limits
  mcp-marketplace:
    build:
      context: .
      dockerfile: apps/mcp-marketplace/Dockerfile
    container_name: securewatch_mcp_marketplace
    ports:
      - "4010:4010"
    environment:
      - NODE_ENV=development
      - MCP_MARKETPLACE_PORT=4010
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch_dev
      - REDIS_URL=redis://:securewatch_dev@redis:6379
      - MCP_AGGREGATOR_URL=https://mcpmarket.com/server/rss-buhe
      - LOG_LEVEL=INFO
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.1'
    restart: unless-stopped
    networks:
      - securewatch_network

  # Kafka for log ingestion - Enhanced with resource limits
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: securewatch_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'
    restart: unless-stopped
    networks:
      - securewatch_network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: securewatch_kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'
    restart: unless-stopped
    networks:
      - securewatch_network

  # OpenSearch for log search - Enhanced with resource limits
  opensearch:
    image: opensearchproject/opensearch:3.0.0
    container_name: securewatch_opensearch
    environment:
      - cluster.name=securewatch-cluster
      - node.name=opensearch-node
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
      - plugins.security.disabled=true
      - plugins.security.ssl.http.enabled=false
      - plugins.security.ssl.transport.enabled=false
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=SecureWatch123!
      - action.auto_create_index=true
      - indices.query.bool.max_clause_count=10000
      - search.max_buckets=40000
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=85%
      - cluster.routing.allocation.disk.watermark.high=90%
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\\|yellow\"'"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s  # OpenSearch needs more time to start
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '0.5'
    restart: unless-stopped
    networks:
      - securewatch_network

  # OpenSearch Dashboards for visualization - Enhanced with resource limits
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:3.0.0
    container_name: securewatch_opensearch_dashboards
    ports:
      - "5601:5601"
    environment:
      - 'OPENSEARCH_HOSTS=["http://opensearch:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true"
      - "SERVER_BASEPATH="
      - "SERVER_REWRITEBASEPATH=false"
      - "OPENSEARCH_DASHBOARDS_DEFAULTAPPID=dashboard"
      - "MAP_INCLUDEELASTICSEARCHMAPSINTELEMETRY=false"
    depends_on:
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status | grep -q '\"state\":\"green\"'"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'
    restart: unless-stopped
    networks:
      - securewatch_network

  # Correlation Engine - Enhanced with resource limits
  correlation-engine:
    build:
      context: ./apps/correlation-engine
      dockerfile: Dockerfile
    container_name: securewatch_correlation_engine
    environment:
      - NODE_ENV=development
      - PORT=4005
      - CORRELATION_ENGINE_PORT=4005
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch_dev
      - REDIS_URL=redis://:securewatch_dev@redis:6379
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
      - MAX_CORRELATION_WINDOW=300
      - MAX_RULES_PER_MINUTE=1000
    ports:
      - "4005:4005"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4005/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.25'
    restart: unless-stopped
    networks:
      - securewatch_network

  # KQL Analytics Engine - Enhanced with resource limits
  analytics-engine:
    build:
      context: ./apps/analytics-engine
      dockerfile: Dockerfile
    container_name: securewatch_analytics_engine
    environment:
      - NODE_ENV=development
      - PORT=4003
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch_dev
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=securewatch_dev
      - REDIS_DB=1
      - MAX_QUERY_TIME=300
      - MAX_MEMORY_MB=1024
      - MAX_RESULT_ROWS=50000
      - MAX_CONCURRENT_QUERIES=5
      - MAX_QUERY_COMPLEXITY=100
      - RATE_LIMIT_MAX=100
      - LOG_LEVEL=info
    ports:
      - "4003:4003"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4003/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'
    restart: unless-stopped
    networks:
      - securewatch_network
    volumes:
      - /tmp:/tmp # For log files

networks:
  securewatch_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  opensearch_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local