version: '3.8'

services:
  # =============================================================================
  # INFRASTRUCTURE SERVICES (Tier 1 - Start First)
  # =============================================================================
  
  # PostgreSQL with TimescaleDB - Enhanced for Production
  postgres:
    image: timescale/timescaledb:latest-pg16
    container_name: securewatch_postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./create_tables.sql:/docker-entrypoint-initdb.d/01_init_schema.sql
      - ./infrastructure/database/correlation_schema.sql:/docker-entrypoint-initdb.d/02_correlation_schema.sql
    environment:
      POSTGRES_USER: securewatch
      POSTGRES_PASSWORD: securewatch
      POSTGRES_DB: securewatch
      TS_TUNE_MEMORY: "4GB"
      TS_TUNE_NUM_CPUS: "4"
      POSTGRES_SHARED_PRELOAD_LIBRARIES: "timescaledb"
      POSTGRES_LOG_STATEMENT: "all"
      POSTGRES_LOG_MIN_DURATION_STATEMENT: "1000"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U securewatch -d securewatch && psql -U securewatch -d securewatch -c 'SELECT 1'"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
        reservations:
          memory: 2G
          cpus: "1.0"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Redis Cluster - Enhanced for Production
  redis:
    image: redis:7-alpine
    container_name: securewatch_redis
    ports:
      - "6379:6379"
    command: |
      redis-server 
      --maxmemory 512mb 
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"
        reservations:
          memory: 256M
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: securewatch_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Kafka for log ingestion - Enhanced
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: securewatch_kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
        reservations:
          memory: 1G
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Elasticsearch for log search - Enhanced
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: securewatch_elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
      - indices.query.bool.max_clause_count=10000
      - search.max_buckets=100000
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
        reservations:
          memory: 1G
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # =============================================================================
  # CORE APPLICATION SERVICES (Tier 2 - Start After Infrastructure)
  # =============================================================================

  # Log Ingestion Service - Enhanced
  log-ingestion:
    build:
      context: ./apps/log-ingestion
      dockerfile: Dockerfile
    container_name: securewatch_log_ingestion
    environment:
      - NODE_ENV=production
      - PORT=4002
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKER=kafka:29092
      - ELASTICSEARCH_HOST=elasticsearch:9200
      - LOG_LEVEL=info
      - MAX_BATCH_SIZE=1000
      - BATCH_TIMEOUT_MS=5000
      - MAX_RETRIES=3
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4002:4002"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4002/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 512M
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Search API Service - Enhanced
  search-api:
    build:
      context: ./apps/search-api
      dockerfile: Dockerfile
    container_name: securewatch_search_api
    environment:
      - NODE_ENV=production
      - PORT=4004
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ELASTICSEARCH_HOST=elasticsearch:9200
      - LOG_LEVEL=info
      - MAX_QUERY_TIME=300
      - MAX_MEMORY_MB=2048
      - MAX_RESULT_ROWS=100000
      - MAX_CONCURRENT_QUERIES=10
      - RATE_LIMIT_MAX=100
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4004:4004"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4004/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: "2.0"
        reservations:
          memory: 1G
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Correlation Engine - Enhanced
  correlation-engine:
    build:
      context: ./apps/correlation-engine
      dockerfile: Dockerfile
    container_name: securewatch_correlation_engine
    environment:
      - NODE_ENV=production
      - PORT=4005
      - HOST=0.0.0.0
      - CORRELATION_ENGINE_PORT=4005
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
      - RULE_EVALUATION_INTERVAL=30
      - MAX_CONCURRENT_RULES=50
      - INCIDENT_RETENTION_DAYS=90
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4005:4005"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      log-ingestion:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4005/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 512M
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # Analytics Engine - Enhanced  
  analytics-engine:
    build:
      context: ./apps/analytics-engine
      dockerfile: Dockerfile
    container_name: securewatch_analytics_engine
    environment:
      - NODE_ENV=production
      - PORT=4003
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=1
      - LOG_LEVEL=info
      - MAX_QUERY_TIME=300
      - MAX_MEMORY_MB=2048
      - MAX_RESULT_ROWS=100000
      - MAX_CONCURRENT_QUERIES=10
      - MAX_QUERY_COMPLEXITY=100
      - RATE_LIMIT_MAX=100
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4003:4003"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      search-api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4003/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: "2.0"
        reservations:
          memory: 1G
          cpus: "0.5"
    restart: unless-stopped
    volumes:
      - /tmp:/tmp
    networks:
      - securewatch_network

  # MCP Marketplace Service - Enhanced
  mcp-marketplace:
    build:
      context: .
      dockerfile: apps/mcp-marketplace/Dockerfile
    container_name: securewatch_mcp_marketplace
    ports:
      - "4006:4006"
    environment:
      - NODE_ENV=production
      - MCP_MARKETPLACE_PORT=4006
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - REDIS_URL=redis://redis:6379
      - MCP_AGGREGATOR_URL=https://mcpmarket.com/server/rss-buhe
      - LOG_LEVEL=info
      - CACHE_TTL=3600
      - MAX_CONCURRENT_DOWNLOADS=5
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4006/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 256M
          cpus: "0.25"
    restart: unless-stopped
    networks:
      - securewatch_network

  # =============================================================================
  # NEW SERVICES (User-Modifiable Section)
  # =============================================================================

  # New Reporting Service
  new-reporting-service:
    build:
      context: ./apps/new-reporting-service
      dockerfile: Dockerfile
    container_name: securewatch_new_reporting_service
    environment:
      - NODE_ENV=production
      - PORT=4007
      - HOST=0.0.0.0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=securewatch
      - DB_USER=securewatch
      - DB_PASSWORD=securewatch
      - LOG_LEVEL=info
      - REPORT_CACHE_TTL=1800
      - MAX_REPORT_SIZE_MB=50
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4007:4007"
    depends_on:
      postgres:
        condition: service_healthy
      search-api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4007/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.25"
    restart: unless-stopped
    networks:
      - securewatch_network

  # New UEBA Service (Python)
  new-ueba-service:
    build:
      context: ./apps/new-ueba-service
      dockerfile: Dockerfile
    container_name: securewatch_new_ueba_service
    environment:
      - PYTHON_ENV=production
      - PORT=4008
      - HOST=0.0.0.0
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=INFO
      - MODEL_UPDATE_INTERVAL=3600
      - ANOMALY_THRESHOLD=0.8
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4008:4008"
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      correlation-engine:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4008/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 45s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 1G
          cpus: "0.5"
    restart: unless-stopped
    networks:
      - securewatch_network

  # =============================================================================
  # FRONTEND SERVICES (Tier 3 - Start Last)
  # =============================================================================

  # Frontend Application - Enhanced
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: securewatch_frontend
    environment:
      - NODE_ENV=production
      - PORT=4000
      - HOST=0.0.0.0
      - NEXT_PUBLIC_API_BASE_URL=http://localhost:4004
      - NEXT_PUBLIC_CORRELATION_API_URL=http://localhost:4005
      - NEXT_PUBLIC_ANALYTICS_API_URL=http://localhost:4003
      - NEXT_PUBLIC_MCP_API_URL=http://localhost:4006
      - NEXT_PUBLIC_REPORTING_API_URL=http://localhost:4007
      - NEXT_PUBLIC_UEBA_API_URL=http://localhost:4008
      - LOG_LEVEL=info
      - PROMETHEUS_ENABLED=true
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    ports:
      - "4000:4000"
    depends_on:
      search-api:
        condition: service_healthy
      correlation-engine:
        condition: service_healthy
      analytics-engine:
        condition: service_healthy
      mcp-marketplace:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 256M
          cpus: "0.25"
    restart: unless-stopped
    networks:
      - securewatch_network

  # =============================================================================
  # OPTIONAL VISUALIZATION SERVICES
  # =============================================================================

  # Kibana for visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: securewatch_kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      SERVER_PUBLICBASEURL: http://localhost:5601
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "0.5"
        reservations:
          memory: 512M
          cpus: "0.25"
    restart: unless-stopped
    networks:
      - securewatch_network

# =============================================================================
# NETWORK AND VOLUME CONFIGURATION
# =============================================================================

networks:
  securewatch_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  kafka_data:
    driver: local