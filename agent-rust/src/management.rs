// Remote management gRPC server for agent control and monitoring

use crate::config::ManagementConfig;
use crate::errors::ManagementError;
use crate::buffer::BufferStats;
use crate::collectors::CollectorStatus;
use crate::parsers::ParserStats;
use crate::transport::TransportStats;
use std::net::SocketAddr;
use std::sync::Arc;
use tokio::sync::{Mutex, RwLock};
use tonic::{transport::Server, Request, Response, Status};
use tracing::{info, warn, error, debug};

// Include generated gRPC code
pub mod agent_management {
    tonic::include_proto!("agent_management");
}

use agent_management::{
    agent_management_server::{AgentManagement, AgentManagementServer},
    *,
};

pub struct AgentManagementService {
    agent_id: String,
    start_time: std::time::Instant,
    config: ManagementConfig,
    
    // Shared state from other components
    buffer_stats: Arc<Mutex<BufferStats>>,
    collector_statuses: Arc<RwLock<Vec<CollectorStatus>>>,
    parser_stats: Arc<RwLock<Vec<ParserStats>>>,
    transport_stats: Arc<RwLock<Option<TransportStats>>>,
    
    // Runtime statistics
    events_processed: Arc<Mutex<u64>>,
    events_sent: Arc<Mutex<u64>>,
    events_failed: Arc<Mutex<u64>>,
    events_dropped: Arc<Mutex<u64>>,
    
    // Configuration reload callback
    config_reload_callback: Option<Arc<dyn Fn() -> Result<(), String> + Send + Sync>>,
}

impl AgentManagementService {
    pub fn new(
        agent_id: String,
        config: ManagementConfig,
        buffer_stats: Arc<Mutex<BufferStats>>,
    ) -> Self {
        Self {
            agent_id,
            start_time: std::time::Instant::now(),
            config,
            buffer_stats,
            collector_statuses: Arc::new(RwLock::new(Vec::new())),
            parser_stats: Arc::new(RwLock::new(Vec::new())),
            transport_stats: Arc::new(RwLock::new(None)),
            events_processed: Arc::new(Mutex::new(0)),
            events_sent: Arc::new(Mutex::new(0)),
            events_failed: Arc::new(Mutex::new(0)),
            events_dropped: Arc::new(Mutex::new(0)),
            config_reload_callback: None,
        }
    }
    
    pub fn set_collector_statuses(&self, statuses: Vec<CollectorStatus>) {
        tokio::spawn({
            let collector_statuses = self.collector_statuses.clone();
            async move {
                let mut guard = collector_statuses.write().await;
                *guard = statuses;
            }
        });
    }
    
    pub fn set_parser_stats(&self, stats: Vec<ParserStats>) {
        tokio::spawn({
            let parser_stats = self.parser_stats.clone();
            async move {
                let mut guard = parser_stats.write().await;
                *guard = stats;
            }
        });
    }
    
    pub fn set_transport_stats(&self, stats: TransportStats) {
        tokio::spawn({
            let transport_stats = self.transport_stats.clone();
            async move {
                let mut guard = transport_stats.write().await;
                *guard = Some(stats);
            }
        });
    }
    
    pub fn set_config_reload_callback<F>(&mut self, callback: F)
    where
        F: Fn() -> Result<(), String> + Send + Sync + 'static,
    {
        self.config_reload_callback = Some(Arc::new(callback));
    }
    
    async fn get_system_resources(&self) -> SystemResources {
        use sysinfo::{System, SystemExt, CpuExt};
        
        let mut system = System::new_all();
        system.refresh_all();
        
        let total_memory = system.total_memory();
        let used_memory = system.used_memory();
        let memory_usage = if total_memory > 0 {
            (used_memory as f64 / total_memory as f64) * 100.0
        } else {
            0.0
        };
        
        // Get CPU usage (averaged across all cores)
        let cpu_usage = system.cpus().iter()
            .map(|cpu| cpu.cpu_usage())
            .sum::<f32>() / system.cpus().len() as f32;
        
        // For simplicity, using memory stats for disk as well
        // In production, you'd want to check actual disk usage
        SystemResources {
            cpu_usage_percent: cpu_usage as f64,
            memory_used_bytes: used_memory,
            memory_total_bytes: total_memory,
            memory_usage_percent: memory_usage,
            disk_used_bytes: used_memory, // Placeholder
            disk_total_bytes: total_memory, // Placeholder
        }
    }
    
    fn validate_auth_token<T>(&self, request: &Request<T>) -> Result<(), Status> {
        if let Some(expected_token) = &self.config.auth_token {
            if let Some(auth_header) = request.metadata().get("authorization") {
                if let Ok(auth_str) = auth_header.to_str() {
                    if auth_str.starts_with("Bearer ") {
                        let token = &auth_str[7..]; // Remove "Bearer " prefix
                        if token == expected_token {
                            return Ok(());
                        }
                    }
                }
            }
            return Err(Status::unauthenticated("Invalid or missing authentication token"));
        }
        Ok(()) // No auth required if token is not configured
    }
}

#[tonic::async_trait]
impl AgentManagement for AgentManagementService {
    async fn get_health(&self, request: Request<Empty>) -> Result<Response<HealthResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游니 Health check requested");
        
        let system_resources = self.get_system_resources().await;
        let buffer_stats = self.buffer_stats.lock().await;
        let collector_statuses = self.collector_statuses.read().await;
        
        let active_collectors = collector_statuses.iter()
            .filter(|status| status.running)
            .count() as i32;
        
        let response = HealthResponse {
            status: "healthy".to_string(),
            agent_id: self.agent_id.clone(),
            version: env!("CARGO_PKG_VERSION").to_string(),
            uptime_seconds: self.start_time.elapsed().as_secs() as i64,
            system_resources: Some(system_resources),
            backpressure_active: buffer_stats.backpressure_active,
            active_collectors,
        };
        
        Ok(Response::new(response))
    }
    
    async fn get_metrics(&self, request: Request<Empty>) -> Result<Response<MetricsResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游늵 Metrics requested");
        
        let events_processed = *self.events_processed.lock().await;
        let events_sent = *self.events_sent.lock().await;
        let events_failed = *self.events_failed.lock().await;
        let events_dropped = *self.events_dropped.lock().await;
        
        // Calculate events per second (simplified)
        let uptime_seconds = self.start_time.elapsed().as_secs();
        let events_per_second = if uptime_seconds > 0 {
            events_processed as f64 / uptime_seconds as f64
        } else {
            0.0
        };
        
        let collector_statuses = self.collector_statuses.read().await;
        let collector_metrics: Vec<CollectorMetrics> = collector_statuses.iter()
            .map(|status| CollectorMetrics {
                name: status.name.clone(),
                source_type: status.name.clone(), // Simplified
                events_collected: 0, // Would need to track this
                events_failed: 0,   // Would need to track this
                is_running: status.running,
                last_error: "".to_string(), // Would need to track this
            })
            .collect();
        
        let response = MetricsResponse {
            events_processed,
            events_sent,
            events_failed,
            events_dropped,
            events_per_second,
            bytes_processed: 0, // Would need to track this
            bytes_sent: 0,     // Would need to track this
            last_activity_timestamp: chrono::Utc::now().timestamp(),
            collector_metrics,
        };
        
        Ok(Response::new(response))
    }
    
    async fn set_log_level(&self, request: Request<LogLevelRequest>) -> Result<Response<LogLevelResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        let req = request.into_inner();
        let new_level = req.level.to_lowercase();
        
        info!("游댢 Log level change requested: {}", new_level);
        
        // Validate log level
        let valid_levels = ["trace", "debug", "info", "warn", "error"];
        if !valid_levels.contains(&new_level.as_str()) {
            return Ok(Response::new(LogLevelResponse {
                success: false,
                message: format!("Invalid log level '{}'. Valid levels: {:?}", new_level, valid_levels),
                previous_level: "unknown".to_string(),
                new_level: new_level.clone(),
            }));
        }
        
        // In a real implementation, you'd change the tracing subscriber's max level here
        // For now, we'll just acknowledge the request
        warn!("丘멆잺  Dynamic log level changes not fully implemented");
        
        let response = LogLevelResponse {
            success: true,
            message: format!("Log level changed to {}", new_level),
            previous_level: "info".to_string(), // Would track the actual previous level
            new_level,
        };
        
        Ok(Response::new(response))
    }
    
    async fn get_collector_status(&self, request: Request<Empty>) -> Result<Response<CollectorStatusResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游니 Collector status requested");
        
        let collector_statuses = self.collector_statuses.read().await;
        let collectors: Vec<agent_management::CollectorStatus> = collector_statuses.iter()
            .map(|status| agent_management::CollectorStatus {
                name: status.name.clone(),
                source_type: status.name.clone(), // Simplified
                running: status.running,
                configuration: "{}".to_string(), // Would serialize actual config
                last_error: "".to_string(),
                last_activity: chrono::Utc::now().timestamp(),
            })
            .collect();
        
        let response = CollectorStatusResponse { collectors };
        Ok(Response::new(response))
    }
    
    async fn get_parser_info(&self, request: Request<Empty>) -> Result<Response<ParserInfoResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游니 Parser info requested");
        
        let parser_stats = self.parser_stats.read().await;
        let parsers: Vec<ParserInfo> = parser_stats.iter()
            .map(|stats| ParserInfo {
                name: stats.name.clone(),
                source_type: stats.source_type.clone(),
                parser_type: stats.parser_type.clone(),
                pattern: "".to_string(), // Would include actual pattern
                field_mappings: vec![], // Would include actual mappings
            })
            .collect();
        
        let response = ParserInfoResponse { parsers };
        Ok(Response::new(response))
    }
    
    async fn get_buffer_stats(&self, request: Request<Empty>) -> Result<Response<BufferStatsResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游니 Buffer stats requested");
        
        let buffer_stats = self.buffer_stats.lock().await;
        
        let response = BufferStatsResponse {
            memory_events: buffer_stats.memory_events as u64,
            disk_events: buffer_stats.disk_events as u64,
            total_bytes: buffer_stats.total_bytes,
            backpressure_active: buffer_stats.backpressure_active,
            events_processed: buffer_stats.events_processed,
            events_dropped: buffer_stats.events_dropped,
            memory_usage_percent: 0.0, // Would calculate this
            disk_usage_percent: 0.0,   // Would calculate this
        };
        
        Ok(Response::new(response))
    }
    
    async fn reload_config(&self, request: Request<Empty>) -> Result<Response<ReloadConfigResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        info!("游댃 Configuration reload requested");
        
        if let Some(callback) = &self.config_reload_callback {
            match callback() {
                Ok(_) => {
                    let response = ReloadConfigResponse {
                        success: true,
                        message: "Configuration reloaded successfully".to_string(),
                        changes_detected: vec!["All components refreshed".to_string()],
                        errors: vec![],
                    };
                    Ok(Response::new(response))
                }
                Err(e) => {
                    let response = ReloadConfigResponse {
                        success: false,
                        message: format!("Configuration reload failed: {}", e),
                        changes_detected: vec![],
                        errors: vec![e],
                    };
                    Ok(Response::new(response))
                }
            }
        } else {
            let response = ReloadConfigResponse {
                success: false,
                message: "Configuration reload not available".to_string(),
                changes_detected: vec![],
                errors: vec!["No reload callback configured".to_string()],
            };
            Ok(Response::new(response))
        }
    }
    
    async fn get_transport_stats(&self, request: Request<Empty>) -> Result<Response<TransportStatsResponse>, Status> {
        self.validate_auth_token(&request)?;
        
        debug!("游니 Transport stats requested");
        
        let transport_stats = self.transport_stats.read().await;
        
        if let Some(stats) = transport_stats.as_ref() {
            let response = TransportStatsResponse {
                server_url: stats.server_url.clone(),
                tls_enabled: stats.tls_enabled,
                compression_enabled: stats.compression_enabled,
                batch_size: stats.batch_size as u32,
                retry_attempts: stats.retry_attempts as u32,
                requests_sent: 0,    // Would track this
                requests_failed: 0,  // Would track this
                bytes_sent: 0,       // Would track this
                average_latency_ms: 0.0, // Would track this
                last_error: "".to_string(),
                last_success_timestamp: chrono::Utc::now().timestamp(),
            };
            Ok(Response::new(response))
        } else {
            Err(Status::unavailable("Transport statistics not available"))
        }
    }
}

pub struct ManagementServer {
    service: AgentManagementService,
    config: ManagementConfig,
}

impl ManagementServer {
    pub fn new(
        agent_id: String,
        config: ManagementConfig,
        buffer_stats: Arc<Mutex<BufferStats>>,
    ) -> Self {
        let service = AgentManagementService::new(agent_id, config.clone(), buffer_stats);
        
        Self { service, config }
    }
    
    pub async fn start(&self) -> Result<(), ManagementError> {
        if !self.config.enabled {
            info!("游뛂 Management server is disabled");
            return Ok(());
        }
        
        info!("游깷 Management server configured but simplified for demo");
        
        // In a full implementation, this would start the actual gRPC server
        // For now, just return Ok to allow compilation
        Ok(())
    }
    
    pub fn get_service(&self) -> &AgentManagementService {
        &self.service
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::buffer::BufferStats;
    
    #[tokio::test]
    async fn test_management_service_creation() {
        let config = ManagementConfig {
            enabled: true,
            bind_address: "127.0.0.1".to_string(),
            port: 9091,
            auth_token: None,
        };
        
        let buffer_stats = Arc::new(Mutex::new(BufferStats {
            memory_events: 0,
            disk_events: 0,
            total_bytes: 0,
            backpressure_active: false,
            events_processed: 0,
            events_dropped: 0,
        }));
        
        let service = AgentManagementService::new(
            "test-agent".to_string(),
            config,
            buffer_stats,
        );
        
        // Test that service was created successfully
        assert_eq!(service.agent_id, "test-agent");
    }
}